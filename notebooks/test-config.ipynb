{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7f715-29a1-4172-b120-b9ab828911f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vistiq.core import StackProcessor, StackProcessorConfig\n",
    "from vistiq.preprocess import DoGConfig, DoG\n",
    "from vistiq.seg import OtsuThresholdConfig, OtsuThreshold, LocalThresholdConfig, LocalThreshold\n",
    "from vistiq.seg import LabellerConfig, Labeller\n",
    "from vistiq.seg import RegionAnalyzerConfig, RegionAnalyzer, RegionFilterConfig, RegionFilter, RangeFilterConfig, RangeFilter\n",
    "from vistiq.seg import SegmenterConfig, Segmenter\n",
    "from vistiq.utils import ArrayIteratorConfig, ArrayIterator, masks_to_labels\n",
    "from vistiq.analysis import CoincidenceDetectorConfig, CoincidenceDetector\n",
    "\n",
    "import numpy as np\n",
    "import stackview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb99c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"~/Documents/SDS_/projects/Siegrist/Microsam_Segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "import os\n",
    "from bioio import BioImage\n",
    "from vistiq.utils import load_image\n",
    "\n",
    "# Expand the path from cell 1\n",
    "base_path = Path(path).expanduser()\n",
    "\n",
    "# Common image file extensions\n",
    "IMAGE_EXTENSIONS = {'.tif', '.tiff', '.png', '.jpg', '.jpeg', '.bmp', '.gif', '.nd2', \n",
    "                    '.czi', '.lif', '.ome.tif', '.ome.tiff', '.zarr', '.svs', '.vsi'}\n",
    "\n",
    "# Recursively get list of all image files in the directory and subdirectories\n",
    "file_list = []\n",
    "if base_path.exists() and base_path.is_dir():\n",
    "    # Use rglob to recursively search for all files\n",
    "    all_files = sorted(base_path.rglob('*'))\n",
    "    # Filter to only image files (not directories) and get relative paths\n",
    "    file_list = [str(f.relative_to(base_path)) for f in all_files \n",
    "                 if f.is_file() and f.suffix.lower() in IMAGE_EXTENSIONS]\n",
    "    if not file_list:\n",
    "        file_list = [\"No image files found\"]\n",
    "else:\n",
    "    file_list = [\"Directory not found\"]\n",
    "\n",
    "# Create file dropdown widget\n",
    "file_dropdown = widgets.Dropdown(\n",
    "    options=file_list,\n",
    "    value=file_list[0] if file_list else None,\n",
    "    description='File:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Create scene dropdown widget (will be updated when file is selected)\n",
    "scene_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Scene:',\n",
    "    disabled=True,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Create channel selector widget (will be updated when file or scene is selected)\n",
    "# Using SelectMultiple to allow selection of multiple channels\n",
    "channel_dropdown = widgets.SelectMultiple(\n",
    "    options=[],\n",
    "    description='Channels:',\n",
    "    disabled=True,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px', height='150px')\n",
    ")\n",
    "\n",
    "# Initialize img variable in global namespace\n",
    "img = None\n",
    "metadata = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6133f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_channels(file_path_str, scene_index=None):\n",
    "    \"\"\"Update channel dropdown based on file and scene selection.\"\"\"\n",
    "    # Disable channel dropdown while loading\n",
    "    channel_dropdown.disabled = True\n",
    "    channel_dropdown.options = [\"Loading...\"]\n",
    "    \n",
    "    try:\n",
    "        # Use bioio to get available channels\n",
    "        reader = BioImage(str(file_path_str))\n",
    "        \n",
    "        # Set scene if provided\n",
    "        if scene_index is not None:\n",
    "            reader.set_scene(scene_index)\n",
    "        \n",
    "        # Try to get channel information\n",
    "        # Check if reader has channel information\n",
    "        if hasattr(reader, 'channel_names') and reader.channel_names:\n",
    "            channel_names = reader.channel_names\n",
    "            if isinstance(channel_names, (list, tuple)):\n",
    "                channel_options = [f\"Channel {i}: {name}\" if name else f\"Channel {i}\" \n",
    "                                 for i, name in enumerate(channel_names)]\n",
    "            else:\n",
    "                num_channels = len(channel_names) if hasattr(channel_names, '__len__') else 1\n",
    "                channel_options = [f\"Channel {i}\" for i in range(num_channels)]\n",
    "        elif hasattr(reader, 'dims') and 'C' in reader.dims:\n",
    "            # Try to get channel dimension from xarray\n",
    "            try:\n",
    "                xdata = reader.xarray_dask_data\n",
    "                if hasattr(xdata, 'dims') and 'C' in xdata.dims:\n",
    "                    num_channels = xdata.dims['C']\n",
    "                    channel_options = [f\"Channel {i}\" for i in range(num_channels)]\n",
    "                else:\n",
    "                    channel_options = [\"Channel 0 (only channel)\"]\n",
    "            except:\n",
    "                channel_options = [\"Channel 0 (only channel)\"]\n",
    "        else:\n",
    "            # Try to get shape and infer channels\n",
    "            try:\n",
    "                test_data = reader.get_image_data()\n",
    "                if test_data is not None and hasattr(test_data, 'shape'):\n",
    "                    # Check if last dimension might be channels (typically for RGB)\n",
    "                    if test_data.ndim >= 3 and test_data.shape[-1] in [1, 3, 4]:\n",
    "                        num_channels = test_data.shape[-1]\n",
    "                        channel_options = [f\"Channel {i}\" for i in range(num_channels)]\n",
    "                    else:\n",
    "                        channel_options = [\"Channel 0 (only channel)\"]\n",
    "                else:\n",
    "                    channel_options = [\"Channel 0 (only channel)\"]\n",
    "            except:\n",
    "                channel_options = [\"Channel 0 (only channel)\"]\n",
    "        \n",
    "        channel_dropdown.options = channel_options\n",
    "        # For SelectMultiple, value should be a tuple/list, default to first channel if available\n",
    "        channel_dropdown.value = (channel_options[0],) if channel_options else ()\n",
    "        channel_dropdown.disabled = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        channel_dropdown.options = [f\"Error: {str(e)}\"]\n",
    "        channel_dropdown.disabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scenes(change):\n",
    "    \"\"\"Update scene dropdown when file selection changes.\"\"\"\n",
    "    selected_relative_path = change['new']\n",
    "    \n",
    "    # Check if we have a valid selection\n",
    "    if not selected_relative_path or selected_relative_path in [\"Directory not found\", \"No image files found\"]:\n",
    "        scene_dropdown.options = []\n",
    "        scene_dropdown.disabled = True\n",
    "        channel_dropdown.options = []\n",
    "        channel_dropdown.disabled = True\n",
    "        return\n",
    "    \n",
    "    if not base_path.exists() or not base_path.is_dir():\n",
    "        scene_dropdown.options = [\"Directory not found\"]\n",
    "        scene_dropdown.disabled = True\n",
    "        channel_dropdown.options = []\n",
    "        channel_dropdown.disabled = True\n",
    "        return\n",
    "    \n",
    "    # Construct full path by joining base_path with relative path\n",
    "    file_path = base_path / selected_relative_path\n",
    "    \n",
    "    # Disable scene dropdown while loading\n",
    "    scene_dropdown.disabled = True\n",
    "    scene_dropdown.options = [\"Loading...\"]\n",
    "    \n",
    "    try:\n",
    "        # Use bioio to get available scenes\n",
    "        reader = BioImage(str(file_path))\n",
    "        scenes = reader.scenes\n",
    "        \n",
    "        # Handle None or empty scenes\n",
    "        if scenes is None:\n",
    "            scene_dropdown.options = [\"No scenes found (scenes is None)\"]\n",
    "            scene_dropdown.disabled = True\n",
    "            update_channels(str(file_path), None)\n",
    "            return\n",
    "        \n",
    "        # Check if scenes is iterable and has length\n",
    "        try:\n",
    "            num_scenes = len(scenes)\n",
    "        except (TypeError, AttributeError):\n",
    "            scene_dropdown.options = [\"No scenes found (cannot get length)\"]\n",
    "            scene_dropdown.disabled = True\n",
    "            update_channels(str(file_path), None)\n",
    "            return\n",
    "        \n",
    "        if num_scenes > 0:\n",
    "            if num_scenes == 1:\n",
    "                # If only one scene, show it clearly\n",
    "                scene_options = [\"Scene 0 (only scene)\"]\n",
    "            else:\n",
    "                # Multiple scenes\n",
    "                scene_options = [f\"Scene {i}\" for i in range(num_scenes)]\n",
    "            scene_dropdown.options = scene_options\n",
    "            scene_dropdown.value = scene_options[0]\n",
    "            scene_dropdown.disabled = False\n",
    "            \n",
    "            # Update channels for the first scene\n",
    "            update_channels(str(file_path), 0)\n",
    "        else:\n",
    "            scene_dropdown.options = [\"No scenes found\"]\n",
    "            scene_dropdown.disabled = True\n",
    "            update_channels(str(file_path), None)\n",
    "    except Exception as e:\n",
    "        scene_dropdown.options = [f\"Error: {str(e)}\"]\n",
    "        scene_dropdown.disabled = True\n",
    "        channel_dropdown.options = []\n",
    "        channel_dropdown.disabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_channels_on_scene_change(change):\n",
    "    \"\"\"Update channels when scene selection changes.\"\"\"\n",
    "    selected_relative_path = file_dropdown.value\n",
    "    selected_scene = change['new']\n",
    "    \n",
    "    # Check if we have valid selections\n",
    "    if not selected_relative_path or selected_relative_path in [\"Directory not found\", \"No image files found\"]:\n",
    "        return\n",
    "    \n",
    "    if not selected_scene or selected_scene in [\"No scenes found\", \"Loading...\"] or selected_scene.startswith(\"Error:\"):\n",
    "        return\n",
    "    \n",
    "    # Extract scene index\n",
    "    try:\n",
    "        scene_parts = selected_scene.split()\n",
    "        if len(scene_parts) >= 2:\n",
    "            scene_str = scene_parts[1]\n",
    "            scene_index = int(scene_str)\n",
    "            file_path = base_path / selected_relative_path\n",
    "            update_channels(str(file_path), scene_index)\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link file dropdown to scene update - this will trigger update_scenes whenever value changes\n",
    "file_dropdown.observe(update_scenes, names='value')\n",
    "\n",
    "# Link scene dropdown to channel update - this will trigger update_channels_on_scene_change when scene changes\n",
    "scene_dropdown.observe(update_channels_on_scene_change, names='value')\n",
    "\n",
    "# Initial update to populate scenes and channels for the first file\n",
    "if file_list and file_list[0] not in [\"Directory not found\", \"No image files found\"]:\n",
    "    update_scenes({'new': file_list[0], 'old': None, 'owner': file_dropdown, 'type': 'change'})\n",
    "\n",
    "# Create load button\n",
    "load_button = widgets.Button(\n",
    "    description='Load Scene',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Load the selected scene from the selected file',\n",
    "    icon='check',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "# Output widget to display status messages\n",
    "status_output = widgets.Output()\n",
    "\n",
    "def load_scene(button):\n",
    "    \"\"\"Load the selected scene from the selected file into img variable.\"\"\"\n",
    "    with status_output:\n",
    "        status_output.clear_output()\n",
    "        \n",
    "        # Get selected file and scene\n",
    "        selected_relative_path = file_dropdown.value\n",
    "        selected_scene = scene_dropdown.value\n",
    "        \n",
    "        # Get selected channel\n",
    "        selected_channel = channel_dropdown.value\n",
    "        \n",
    "        # Validate selections\n",
    "        if not selected_relative_path or selected_relative_path in [\"Directory not found\", \"No image files found\"]:\n",
    "            print(\"Error: Please select a valid file\")\n",
    "            return\n",
    "        \n",
    "        # Check if selected_scene is None or invalid\n",
    "        if selected_scene is None:\n",
    "            print(\"Error: No scene selected\")\n",
    "            return\n",
    "        \n",
    "        # Check if scene is a string (should always be)\n",
    "        if not isinstance(selected_scene, str):\n",
    "            print(f\"Error: Scene selection is not a string: {type(selected_scene)}\")\n",
    "            return\n",
    "        \n",
    "        # Check if scene is in invalid states\n",
    "        invalid_scenes = [\"No scenes found\", \"Loading...\"]\n",
    "        try:\n",
    "            is_invalid = any(invalid in selected_scene for invalid in invalid_scenes) or selected_scene.startswith(\"Error:\")\n",
    "        except (TypeError, AttributeError):\n",
    "            print(f\"Error: Cannot check scene validity for: {selected_scene}\")\n",
    "            return\n",
    "        \n",
    "        if is_invalid:\n",
    "            print(f\"Error: Invalid scene selection: {selected_scene}\")\n",
    "            return\n",
    "        \n",
    "        # Construct full path\n",
    "        file_path = base_path / selected_relative_path\n",
    "        \n",
    "        try:\n",
    "            # Extract scene index from \"Scene X\" format\n",
    "            # Handle both \"Scene 0\" and \"Scene 0 (only scene)\" formats\n",
    "            scene_parts = selected_scene.split()\n",
    "            if len(scene_parts) < 2:\n",
    "                print(f\"Error: Cannot parse scene from '{selected_scene}'\")\n",
    "                return\n",
    "            \n",
    "            scene_str = scene_parts[1]  # Get the number part\n",
    "            scene_index = int(scene_str)\n",
    "            \n",
    "            # Extract channel indices if channels are selected\n",
    "            options = {}\n",
    "            channel_indices = []\n",
    "            if selected_channel and len(selected_channel) > 0:\n",
    "                # selected_channel is now a tuple/list of selected channel strings\n",
    "                for channel_str in selected_channel:\n",
    "                    if channel_str.startswith(\"Error:\") or channel_str == \"Loading...\":\n",
    "                        continue\n",
    "                    try:\n",
    "                        # Extract channel index from \"Channel X\" or \"Channel X: name\" format\n",
    "                        channel_parts = channel_str.split()\n",
    "                        if len(channel_parts) >= 2:\n",
    "                            channel_idx_str = channel_parts[1].rstrip(':')\n",
    "                            channel_idx = int(channel_idx_str)\n",
    "                            channel_indices.append(channel_idx)\n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "            \n",
    "            # If channels are selected, handle channel selection\n",
    "            if channel_indices:\n",
    "                # Check if channels are contiguous\n",
    "                sorted_indices = sorted(channel_indices)\n",
    "                is_contiguous = all(sorted_indices[i+1] - sorted_indices[i] == 1 for i in range(len(sorted_indices)-1))\n",
    "                \n",
    "                if len(channel_indices) == 1:\n",
    "                    # Single channel: use slice to keep dimension\n",
    "                    options['C'] = slice(channel_indices[0], channel_indices[0] + 1)\n",
    "                    r = load_image(str(file_path), scene_index=scene_index, options=options, squeeze=True)\n",
    "                    globals()['img'] = r[0]\n",
    "                    globals()[\"metadata\"] = r[1]\n",
    "                elif is_contiguous:\n",
    "                    # Contiguous channels: use slice\n",
    "                    min_channel = min(channel_indices)\n",
    "                    max_channel = max(channel_indices)\n",
    "                    options['C'] = slice(min_channel, max_channel + 1)\n",
    "                    r = load_image(str(file_path), scene_index=scene_index, options=options, squeeze=True)\n",
    "                    globals()['img'] = r[0]\n",
    "                    globals()[\"metadata\"] = r[1]\n",
    "                else:\n",
    "                    # Non-contiguous channels: load all channels first, then select specific ones\n",
    "                    # Load without channel restriction to get all channels\n",
    "                    r = load_image(str(file_path), scene_index=scene_index, squeeze=False)\n",
    "                    all_channels = r[0]\n",
    "                    globals()[\"metadata\"] = r[1]\n",
    "                    # Find the channel dimension (typically the first dimension after spatial dims)\n",
    "                    # For bioio, channels are usually in a specific dimension - try to find it\n",
    "                    # Common patterns: CZYX, TCZYX, etc.\n",
    "                    # We'll try to find dimension with size >= max(channel_indices) + 1\n",
    "                    channel_dim = None\n",
    "                    for dim_idx in range(all_channels.ndim):\n",
    "                        if all_channels.shape[dim_idx] > max(channel_indices):\n",
    "                            channel_dim = dim_idx\n",
    "                            break\n",
    "                    \n",
    "                    if channel_dim is not None:\n",
    "                        # Select the specific channels using advanced indexing\n",
    "                        # Create index array for the channel dimension\n",
    "                        indices = [slice(None)] * all_channels.ndim\n",
    "                        indices[channel_dim] = sorted_indices\n",
    "                        globals()['img'] = all_channels[tuple(indices)]\n",
    "                    else:\n",
    "                        # Fallback: assume channels are in first dimension if shape matches\n",
    "                        if all_channels.shape[0] > max(channel_indices):\n",
    "                            globals()['img'] = all_channels[sorted_indices]\n",
    "                        else:\n",
    "                            # Couldn't determine channel dimension, load with range\n",
    "                            min_channel = min(channel_indices)\n",
    "                            max_channel = max(channel_indices)\n",
    "                            options['C'] = slice(min_channel, max_channel + 1)\n",
    "                            r = load_image(str(file_path), scene_index=scene_index, options=options, squeeze=True)\n",
    "                            globals()['img'] = r[0]\n",
    "                            globals()[\"metadata\"] = r[1]\n",
    "            else:\n",
    "                # No channels selected, load all\n",
    "                r = load_image(str(file_path), scene_index=scene_index)\n",
    "                globals()['img'] \n",
    "                globals()[\"metadata\"]\n",
    "            \n",
    "            # Get img from globals for printing\n",
    "            img = globals()['img']\n",
    "            metadata = globals()[\"metadata\"]\n",
    "            \n",
    "            if channel_indices:\n",
    "                if len(channel_indices) == 1:\n",
    "                    print(f\"✓ Loaded Scene {scene_index}, Channel {channel_indices[0]} from {selected_relative_path}\")\n",
    "                else:\n",
    "                    print(f\"✓ Loaded Scene {scene_index}, Channels {channel_indices} from {selected_relative_path}\")\n",
    "            else:\n",
    "                print(f\"✓ Loaded Scene {scene_index} from {selected_relative_path}, metadata={metadata}\")\n",
    "            \n",
    "            print(f\"  Image shape: {img.shape}\")\n",
    "            print(f\"  Image dtype: {img.dtype}\")\n",
    "            print(f\"  Image metadata: {metadata}\")\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Invalid scene index format: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading scene: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Link button to load function\n",
    "load_button.on_click(load_scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f761f-8de9-4be4-9c42-04710043596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    file_dropdown, \n",
    "    scene_dropdown, \n",
    "    channel_dropdown,\n",
    "    load_button,\n",
    "    status_output\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bcd54-dfea-416f-9480-630fe880204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogc = DoGConfig(sigma_low=1.0, sigma_high=12.0)\n",
    "dogc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078f67c-16bc-4747-9606-b4b47335dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpn = img[1][40:50]\n",
    "edu = img[0][40:50]\n",
    "\n",
    "dog = DoG(dogc)\n",
    "ddpn = dog.run(dpn)\n",
    "dedu = dog.run(edu)\n",
    "print (ddpn.shape)\n",
    "stackview.slice(np.concatenate([ddpn, dedu], axis=-1), continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47dcdfa-551c-440a-a948-15f0c40c7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vistiq.seg import MicroSAMSegmenterConfig, MicroSAMSegmenter\n",
    "\n",
    "volume_it_cfg = ArrayIteratorConfig(slice_def=(-3, -2, -1))\n",
    "\n",
    "filters = [RangeFilter(RangeFilterConfig(attribute=\"volume\", range=(65,5000)))]\n",
    "ra = RegionAnalyzer(RegionAnalyzerConfig(iterator_config=volume_it_cfg, output_type=\"dataframe\", \n",
    "                           properties=[\"centroid\", \"volume\", \"solidity\", \"aspect_ratio\", \"sphericity\"]))\n",
    "rf = RegionFilter(RegionFilterConfig(filters=filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202d012-870f-4bb9-8480-8789d50af2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmask, dlabels, dresults = MicroSAMSegmenter(MicroSAMSegmenterConfig(region_filter=rf)).run(ddpn)\n",
    "dmask = np.array(dmask)\n",
    "dlabels = np.array(dlabels)\n",
    "print (f\"mask.shape={dmask.shape}, labels.shape={dlabels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295e05e-dcab-44a4-92ba-959c0190049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rac = RegionAnalyzerConfig(iterator_config=volume_it_cfg, output_type=\"dataframe\", \n",
    "                           properties=[\"centroid\", \"bbox\", \"area\", \"solidity\", \"aspect_ratio\", \"circularity\"])\n",
    "ra = RegionAnalyzer(rac)\n",
    "rn = ra.run(dlabels, metadata={\"scale\":(1,1,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afb996-0d6a-4eb3-ad00-9786f52381cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ra.run(dlabels, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916e652-aa65-47b3-b009-7a57da7facfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4f641-fe53-4a16-8bf1-170f2e42bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7199c16-634c-47ca-a7cf-d10fef698b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emask, elabels, eresults = MicroSAMSegmenter(MicroSAMSegmenterConfig()).run(dedu)\n",
    "emask = np.array(emask)\n",
    "elabels = np.array(elabels)\n",
    "print (f\"mask.shape={emask.shape}, labels.shape={elabels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4311d5b-960a-4c69-9636-4eebb4f8f186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa99726-ddb5-4bc6-abab-8a6fa921faaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oc = CoincidenceDetectorConfig(method=\"dice\", mode=\"outline\", iterator_config=volume_it_cfg, threshold=0.1)\n",
    "ovl_results = CoincidenceDetector(oc).run(dlabels, elabels, (\"Dpn\", \"EDU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b3c17-b851-4eb5-82af-872679a5416f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ovl_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e49924-f2d5-4039-9838-8789c8633d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(ovl_results[1][\"Dpn\"]), len(np.unique(dlabels)), np.min(dlabels), np.max(dlabels))\n",
    "ovl_results[1][\"Dpn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19c4c1-00a7-4fed-80c7-55e0fceb7dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stackview.slice(np.concat([dlabels, elabels], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0668779-c5c5-4107-9280-45154b984954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "from napari.utils.colormaps.colormap_utils import label_colormap\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca7461-54ae-4e01-9c70-25420cced63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c71f2-6945-4801-8541-17b1dca79062",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(dpn, colormap=\"red\", blending=\"additive\", scale=metadata[\"used_scale\"])\n",
    "viewer.add_image(edu, colormap=\"green\", blending=\"additive\", scale=metadata[\"used_scale\"])\n",
    "viewer.add_labels(dlabels, features=ovl_results[1][\"Dpn\"], blending=\"additive\", scale=metadata[\"used_scale\"])\n",
    "viewer.add_labels(elabels, features=ovl_results[1][\"EDU\"], blending=\"additive\", scale=metadata[\"used_scale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d24f7d-e349-442b-b8ed-4ac937eca6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedc2ab-6f16-49df-a5ee-05a8917beb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpn_df = ovl_results[1][\"Dpn\"]\n",
    "edu_pos = dpn_df[dpn_df[\"EDU +\"]]\n",
    "edu_neg = dpn_df[~dpn_df[\"EDU +\"]]\n",
    "plus_mask = np.isin(dlabels, edu_pos.index.values)\n",
    "minus_mask = np.isin(dlabels, edu_neg.index.values)\n",
    "\n",
    "labels = masks_to_labels([plus_mask, minus_mask])\n",
    "viewer.add_labels(labels, name=\"Dpn Edu+/Edu-\", features=ovl_results[1][\"Dpn\"], scale=metadata[\"used_scale\"])\n",
    "#viewer.add_image(np.isin(dlabels, edu_pos.index.values), name=f\"edu +\", blending=\"additive\", colormap=\"cyan\", opacity=0.5, scale=metadata[\"used_scale\"]) \n",
    "#viewer.add_image(np.isin(dlabels, edu_neg.index.values), name=f\"edu -\", blending=\"additive\", colormap=\"magenta\", opacity=0.5, scale=metadata[\"used_scale\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2535f8-2bb9-4774-9396-39170e2a3290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mask, labels, results = MicroSAMSegmenter(MicroSAMSegmenterConfig()).run(img[:,30:35,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f2df1-df3a-4103-86ee-7877a86e8906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fceddb-16fb-4690-8f21-2d3372a5198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes=[((1,2,3),(4,5,6)), ((3,4,5),(6,7,8))] #z1, y1, x1, z2, y2, x2\n",
    "bboxes=np.array(bboxes)\n",
    "ndim = bboxes.ndim\n",
    "bbox_array = bboxes.reshape((len(bboxes),2,-1))\n",
    "union_mins = np.min(bbox_array[:, 0, :], axis=0)\n",
    "union_maxs = np.max(bbox_array[:, 1, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72692741-65b6-44e4-bc73-74316ad7f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (union_mins, union_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f28df8-7d5b-4e81-8de3-9ac09aa4fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef84530-a2ad-4936-9f4d-0fb1422afc04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
